{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-1-d4ec7a9218e2>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces  is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face 1 added\n",
      "Face 2 added\n",
      "Face 3 added\n",
      "Face 4 added\n",
      "Face 5 added\n",
      "Face 6 added\n",
      "Face 7 added\n",
      "Face 8 added\n",
      "Face 9 added\n",
      "Face 10 added\n",
      "Face 11 added\n",
      "Face 12 added\n",
      "Face 13 added\n",
      "Face 14 added\n",
      "Face 15 added\n",
      "Face 16 added\n",
      "Face 17 added\n",
      "Face 18 added\n",
      "Face 19 added\n",
      "Face 20 added\n",
      "Face 21 added\n",
      "Face 22 added\n",
      "Face 23 added\n",
      "Face 24 added\n",
      "Face 25 added\n",
      "Face 26 added\n",
      "Face 27 added\n",
      "Face 28 added\n",
      "Face 29 added\n",
      "Face 30 added\n",
      "Face 31 added\n",
      "Face 32 added\n",
      "Face 33 added\n",
      "Face 34 added\n",
      "Face 35 added\n",
      "Face 36 added\n",
      "Face 37 added\n",
      "Face 38 added\n",
      "Face 39 added\n",
      "Face 40 added\n",
      "Face 41 added\n",
      "Face 42 added\n",
      "Face 43 added\n",
      "Face 44 added\n",
      "Face 45 added\n",
      "Face 46 added\n",
      "Face 47 added\n",
      "Face 48 added\n",
      "Face 49 added\n",
      "Face 50 added\n",
      "Face 51 added\n",
      "Face 52 added\n",
      "Face 53 added\n",
      "Face 54 added\n",
      "Face 55 added\n",
      "Face 56 added\n",
      "Face 57 added\n",
      "Face 58 added\n",
      "Face 59 added\n",
      "Face 60 added\n",
      "Face 61 added\n",
      "Face 63 added\n",
      "Face 65 added\n",
      "Face 75 added\n",
      "Face 77 added\n",
      "Face 78 added\n",
      "Face 79 added\n",
      "Face 80 added\n",
      "Face 81 added\n",
      "Face 85 added\n",
      "Face 86 added\n",
      "Face 87 added\n",
      "Face 88 added\n",
      "Face 89 added\n",
      "Face 91 added\n",
      "Face 94 added\n",
      "Face 95 added\n",
      "Face 96 added\n",
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces  is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = './user/rohit/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        count+=1\n",
    "        print(\"Face \"+str(count)+\" added\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained Successfully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "data_path =\"./user/rohit/\"\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path +onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append((np.asarray(images, dtype=np.uint8)))\n",
    "    Labels.append(i)\n",
    "    \n",
    "\n",
    "    \n",
    "Labels = np.asarray(Labels, dtype = np.int32)\n",
    "\n",
    "model = cv2.face_LBPHFaceRecognizer.create()\n",
    "model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"Model Trained Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:41: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:41: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-3-a180754ec664>:41: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pywhatkit\n",
    "from datetime import datetime\n",
    "import smtplib\n",
    "import subprocess as sp\n",
    "import time\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def whatsApp():\n",
    "    now = datetime.now()\n",
    "    hours = int(now.strftime(\"%H\"))\n",
    "    minutes = int(now.strftime(\"%M\")) + 1\n",
    "    pywhatkit.sendwhatmsg('Mobie No.','This is face of Rohit',hours,minutes)\n",
    "    print(\"whatsApp message send\")\n",
    "\n",
    "def email():\n",
    "    server = smtplib.SMTP_SSL(\"smtp.gmail.com\",465)\n",
    "    print(\"Server Start\")\n",
    "    server.login(\"Email_Acc.\",\"Password\")\n",
    "    print(\"login Complete\")\n",
    "    server.sendmail(\"Rohit\",\"rohitjain8909@gmail.com\" , \"this is face of Rohit\")\n",
    "    \n",
    "    server.quit()\n",
    "    print(\"mail send\")\n",
    "    \n",
    "def Instance_EBS():\n",
    "    instance_id = sp.getoutput(\"aws ec2 run-instances --image-id ami-0ad704c126371a549 --instance-type t2.micro --count 1 --subnet-id subnet-0d4e2bb1599be8952 --security-group-ids sg-09a168c7c84e06582 --key-name MyfirstawsKey  --tag-specifications ResourceType=instance,Tags=[{Key=Name,Value=Rohit_Instance}]  --query Instances[*].[InstanceId] --output text\")\n",
    "    print(\"Instance Id : \"+str(instance_id))\n",
    "    volume_id = sp.getoutput(\"aws ec2 create-volume --volume-type gp2 --availability-zone ap-south-1a --size 5 --tag-specifications=ResourceType=volume,Tags=[{Key=Name,Value=Rohit_volume}] --query VolumeId --output text\")\n",
    "    print(\"Volume Id : \"+str(volume_id) )\n",
    "    time.sleep(20)\n",
    "    sp.getoutput(\"aws ec2 attach-volume --volume-id {} --instance-id {} --device /dev/sdf\".format(volume_id,instance_id))\n",
    "    print(\"Volume and Instance Attached\")\n",
    "    \n",
    "def face_detector(img, size=0.5):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "        \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        img1 = img[y:y+h, x:x+w]\n",
    "        img1 = cv2.resize(img1, (200, 200))\n",
    "    return img, img1\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()    \n",
    "    image, face = face_detector(frame)\n",
    "   \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        results = model.predict(face)\n",
    "        \n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is User'\n",
    "            \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "        \n",
    "        if confidence > 86:\n",
    "            cv2.putText(image, \"Hey Rohit\", (250, 450), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )  \n",
    "            email()\n",
    "            whatsApp()\n",
    "            \n",
    "            break     \n",
    "         \n",
    "        elif confidence < 84 :\n",
    "            cv2.putText(image, \"Hey You are another\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            Instance_EBS()\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            cv2.putText(image, \"I dont know, who r you\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13: \n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
